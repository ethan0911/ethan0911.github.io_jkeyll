[
	{
		"title": "CPU Isosurface Ray Tracing of Adaptive Mesh Refinement Data",
		"authors": "Feng Wang, Ingo Wald, Qi Wu, Will Usher and Chris R. Johnson",
		"venue": "IEEE Transactions on Visualization and Computer Graphics",
		"paper_pdf": "assets/papers/Fen-AMR-VIS18.pdf",
		"teaser": "https://i.imgur.com/2rmTeh2.png",
		"thumb": "assets/papers/thumb/tAMR.png",
		"year": 2018,
		"short_title": "AMR",
		"doi": "10.1109/TVCG.2017.2744079",
		"supplemental_video": "https://www.youtube.com/embed/lTNef_kbLKg",
		"presentation_video": "https://www.youtube.com/embed/XzmYdl9rFs0",
		"downloads": [
			{
				"title": "Videos",
				"list": [
					{
						"title": "Analyzing an Expert Session",
						"link": "https://youtu.be/L5tsU8TtgkU"
					},
					{
						"title": "ZED Mixed Reality Prototype",
						"link": "https://youtu.be/t6rPU6hy5tk"
					},
					{
						"title": "VIS17 Fast Forward",
						"link": "https://youtu.be/mZ6YT_y7Kx0"
					}
				]
			}
		],
		"bibtex": "@article{Usher_VRNT_2018,\n
			author={W. Usher and P. Klacansky and F. Federer and P. T. Bremer and A. Knoll and J. Yarch and A. Angelucci and V. Pascucci},\n
			journal={IEEE Transactions on Visualization and Computer Graphics},\n
			title={A {Virtual} {Reality} {Visualization} {Tool} for {Neuron} {Tracing}},\n
			year={2018},\n
			volume={24},\n
			number={1},\n
			pages={994-1003},\n
			doi={10.1109/TVCG.2017.2744079},\n
			ISSN={1077-2626},\n
			month={Jan},\n}",
		"abstract": "Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy—the octant method—which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets",
		"teaser_caption": "A screenshot of our VR neuron tracing tool using the isosurface rendering mode. The dark gray floor represents the extent of the tracked space. Users can orient themselves in the dataset via the minimap (right), which shows the world extent in blue, the current focus region in orange, and the previously traced neuronal structures. The focus region is displayed in the center of the space. The 3D interaction and visualization provides an intuitive environment for exploring the data and a natural interface for neuron tracing, resulting in faster, high-quality traces with less fatigue reported by users compared to existing 2D tools."
	},
	{
		"title": "VisIt-OSPRay: Toward an Exascale Volume Visualization System",
		"authors": "Qi Wu, Will Usher, Steve Petruzza, Sidharth Kumar, Feng Wang,
			Ingo Wald, Valerio Pascucci, and Charles D. Hansen",
		"venue": "Eurographics Symposium on Parallel Graphics and Visualization",
		"paper_pdf": "assets/papers/visit-ospray-egpgv18.pdf",
		"teaser": "https://i.imgur.com/JgAOmst.png",
		"thumb": "assets/papers/thumb/tVisItOSPRay.jpg",
		"year": 2018,
		"short_title": "visit-ospray",
		"doi": "10.2312/pgv.20181091",
		"bibtex": "@inproceedings{Wu_VisItOSPRay_2018,\n
			booktitle = {Eurographics Symposium on Parallel Graphics and Visualization},\n
			editor = {Hank Childs and Fernando Cucchietti},\n
			title = {{VisIt-OSPRay: Toward an Exascale Volume Visualization System}},\n
			author = {Wu, Qi and Usher, Will and Petruzza, Steve and Kumar, Sidharth and Wang, Feng and Wald, Ingo and Pascucci, Valerio and Hansen, Charles D.},\n
			year = {2018},\n
			publisher = {The Eurographics Association},\n
			ISSN = {1727-348X},\n
			ISBN = {978-3-03868-054-3},\n
			DOI = {10.2312/pgv.20181091}\n
		}",
		"abstract": "Large-scale simulations can easily produce data in excess of what can be
		efficiently visualized using production visualization software, making it
		challenging for scientists to gain insights from the results of these 
		simulations.
		This trend is expected to grow with exascale. To meet this challenge,
		and run on the highly parallel hardware being deployed on HPC system,
		rendering systems in production visualization software must be redesigned
		to perform well at these new scales and levels of parallelism.
		In this work, we present VisIt-OSPRay, a high-performance,
		scalable, hybrid-parallel rendering system in VisIt, using OSPRay and IceT, 
		coupled with PIDX for scalable I/O. 
		We examine the scalability and memory efficiency of this system and 
		investigate further areas for improvement to prepare VisIt for 
		upcoming exascale workloads.",
		"teaser_caption": "High-quality interactive volume visualization using VisIt-OSPRay:
		<b>a)</b> volume rendering of O<sub>2</sub> concentration inside a combustion chamber,
		data courtesy of the <a href=\"http://ccmsc.sci.utah.edu/\">University of Utah CCMSC</a>;
		<b>b)</b> volume rendering of the Richtmyer-Meshkov Instability;
		<b>c)</b> visualization of a supernova simulation;
		<b>d)</b> visualization of the aneurysm dataset using volume rendering and streamlines;
		<b>e)</b> scalable volume rendering of the 966GB DNS data on 64 Stampede2 Intel Xeon Phi
		Knight's Landing nodes."
	},
	{
		"title": "Association Rules-Based Multivariate Analysis and Visualization of Spatiotemporal Climate Data",
		"authors": "Feng Wang, Wenwen Li, Sizhe Wang and Chris R. Johnson",
		"venue": "International Journal of Geo-Information",
		"paper_pdf": "assets/papers/ijgi-associationRules.pdf",
		"thumb": "assets/papers/thumb/tAssociationRules.png",
		"year": 2018,
		"short_title": "associationRules18",
		"doi": "10.3390/ijgi7070266",
		"downloads": [
			{
				"title": "Videos",
				"list": [
					{
						"title": "Uintah UASC Coal Boiler Visualization",
						"link": "https://youtu.be/vpJtHTzArq4"
					}
				]
			}
		],
		"bibtex": "@article{Wang_2018,\n
			title = {{Association} {Rules-Based} {Multivariate} {Analysis} and {Visualization} of {Spatiotemporal} {Climate} Data},\n
			volume = {7},\n
		    journal = {{ISPRS} International Journal of Geo-Information}},\n
			publisher = {{MDPI} {AG}},\n
			author = {Feng Wang and Wenwen Li and Sizhe Wang and Chris Johnson},\n
			url = {https://doi.org/10.3390%2Fijgi7070266},\n
			year = {2018},\n
			month = {jul},\n
			number = {7},\n
			doi = {10.3390/ijgi7070266},\n
			pages = {266},\n}",
			"abstract": "Understandingatmosphericphenomenainvolvesanalysisoflarge-scalespatiotemporal multivariate data. The complexity and heterogeneity of such data pose a significant challenge in discovering and understanding the association between multiple climate variables. To tackle this challenge, we present an interactive heuristic visualization system that supports climate scientists and the public in their exploration and analysis of atmospheric phenomena of interest. Three techniques are introduced: (1) web-based spatiotemporal climate data visualization; (2) multiview and multivariate scientific data analysis; and (3) data mining-enabled visual analytics. The Arctic System Reanalysis (ASR) data are used to demonstrate and validate the effectiveness and usefulness of our method through a case study of “The Great Arctic Cyclone of 2012”. The results show that different variables have strong associations near the polar cyclone area. This work also provides techniques for identifying multivariate correlation and for better understanding the driving factors of climate phenomena."
	},
	{
		"title": "CPU Volume Rendering of Adaptive Mesh Refinement Data",
		"authors": "Ingo Wald, Carson Brownlee, Will Usher, Aaron Knoll",
		"venue": "SIGGRAPH Asia 2017 Symposium on Visualization",
		"paper_pdf": "http://sci.utah.edu/~will/papers/cvamr/cvamr.pdf",
		"teaser": "https://i.imgur.com/CqZc3VJ.png",
		"thumb": "https://i.imgur.com/JFShB4G.png",
		"year": 2017,
		"short_title": "cvamr",
		"doi": "10.1145/3139295.3139305",
		"bibtex": "@inproceedings{Wald_CVAMR_2017,\n
			author = {Wald, Ingo and Brownlee, Carson and Usher, Will and Knoll, Aaron},\n
			title = {CPU Volume Rendering of Adaptive Mesh Refinement Data},\n
			booktitle = {SIGGRAPH Asia 2017 Symposium on Visualization},\n
			series = {SA '17},\n
			year = {2017},\n
			isbn = {978-1-4503-5411-0},\n
			location = {Bangkok, Thailand},\n
			pages = {9:1--9:8},\n
			articleno = {9},\n
			numpages = {8},\n
			url = {http://doi.acm.org/10.1145/3139295.3139305},\n
			doi = {10.1145/3139295.3139305},\n
			acmid = {3139305},\n
			publisher = {ACM},\n
			address = {New York, NY, USA},\n
		}",
		"abstract": "Adaptive Mesh Refinement (AMR) methods are widespread
		in scientific computing, and visualizing the resulting data with
		efficient and accurate rendering methods can be vital for enabling 
		interactive data exploration.
		In this work, we
		detail a comprehensive solution for directly volume rendering block-structured 
		(Berger-Colella) AMR data in the
		OSPRay interactive CPU ray tracing framework. In particular, we
		contribute a general method for representing and traversing AMR data
		using a kd-tree structure, and four different reconstruction
		options, one of which in particular (the basis function approach)
		is novel compared to existing methods. We demonstrate our system on two
		types of block-structured AMR data and compressed scalar
		field data, and show how it can be easily used in existing production-ready
		applications through a prototypical integration in the widely used visualization program ParaView.",
		"teaser_caption": "Two examples of our method (integrated within the OSPRay ray tracer):
		Left: 1.8GB Cosmos AMR data, rendered in ParaView. Right: a 57GB NASA Chombo simulation,
		rendered with ambient occlusion and shadows alongside mesh geometry."
	},
	{
		"title": "Progressive CPU Volume Rendering with Sample Accumulation",
		"authors": "Will Usher, Jefferson Amstutz, Carson Brownlee, Aaron Knoll, Ingo Wald",
		"venue": "Eurographics Symposium on Parallel Graphics and Visualization",
		"paper_pdf": "http://sci.utah.edu/~will/papers/savr/savr.pdf",
		"teaser": "https://i.imgur.com/15y1f8I.png",
		"thumb": "https://i.imgur.com/tdxjYs3.png",
		"short_title": "savr",
		"doi": "10.2312/pgv.20171090",
		"gh_user": "ospray",
		"gh_repo": "module_savr",
		"year": 2017,
		"bibtex": "@inproceedings{Usher_SAVR_2017,\n
			booktitle={Eurographics Symposium on Parallel Graphics and Visualization},\n
			editor={Alexandru Telea and Janine Bennett},\n
			title={{Progressive CPU Volume Rendering with Sample Accumulation}},\n
			author={Usher, Will and Amstutz, Jefferson and Brownlee, Carson and Knoll, Aaron and Wald, Ingo},\n
			year={2017},\n
			publisher={The Eurographics Association},\n
			issn={1727-348X},\n
			isbn={978-3-03868-034-5},\n
			doi={10.2312/pgv.20171090},\n}",
		"abstract": "We present a new method for progressive volume rendering by accumulating object-space samples over successively rendered frames. Existing methods for progressive refinement either use image space methods or average pixels over frames, which can blur features or integrate incorrectly with respect to depth. Our approach stores samples along each ray, accumulates new samples each frame into a buffer, and progressively interleaves and integrates these samples. Though this process requires additional memory, it ensures interactivity and is well suited for CPU architectures with large memory and cache. This approach also extends well to distributed rendering in cluster environments. We implement this technique in Intel’s open source OSPRay CPU ray tracing framework and demonstrate that it is particularly useful for rendering volumetric data with costly sampling functions.",
		"teaser_caption": "(a-c) Progressive refinement with Sample-Accumulation Volume Rendering (SAVR) on the 40GB Landing Gear AMR dataset using a prototype AMR sampler. The SAVR algorithm correctly accumulates frames to progressively refine the image. After 16 frames of accumulation the volume is sampled at the Nyquist limit, with some small noise, by 32 frames the noise has been removed. SAVR extends to distributed data, in (d) we show the 1TB DNS dataset, a 10240×7680×1536 uniform grid, rendered interactively across 64 second-generation Intel Xeon Phi \"Knights Landing\" (KNL) processor nodes on Stampede 1.5 at a 6144×1024 resolution. While interacting, our method achieves around 5.73 FPS."
	},
	{
		"title": "In Situ Exploration of Particle Simulations with CPU Ray Tracing",
		"authors": "Will Usher, Ingo Wald, Aaron Knoll, Michael Papka, Valerio Pascucci",
		"venue": "Supercomputing Frontiers and Innovations",
		"paper_pdf": "http://sci.utah.edu/~will/papers/in_situ_particles/in_situ_particles.pdf",
		"teaser": "https://i.imgur.com/DO3JqOb.png",
		"thumb": "https://i.imgur.com/gieTAy3.png",
		"short_title": "isp-jsfi",
		"doi": "10.14529/jsfi160401",
		"gh_user": "Twinklebear",
		"gh_repo": "in-situ-particles",
		"year": 2016,
		"bibtex": "@article{Usher_InSituParticles_2016,\n
			author={Will Usher and Ingo Wald and Aaron Knoll and Michael Papka and Valerio Pascucci},\n
			title={In {Situ} {Exploration} of {Particle} {Simulations} with {CPU} {Ray} {Tracing}},\n
			journal={Supercomputing Frontiers and Innovations},\n
			volume={3},\n
			number={4},\n
			year={2016},\n
			issn={2313-8734},\n
			doi={10.14529/jsfi160401},\n}",
		"abstract": "We present a system for interactive in situ visualization of large particle simulations, suitable for general CPU-based HPC architectures. As simulations grow in scale, in situ methods are needed to alleviate IO bottlenecks and visualize data at full spatio-temporal resolution. We use a lightweight loosely-coupled layer serving distributed data from the simulation to a data-parallel renderer running in separate processes. Leveraging the OSPRay ray tracing framework for visualization and balanced P-k-d trees, we can render simulation data in real-time, as they arrive, with negligible memory overhead. This flexible solution allows users to perform exploratory in situ visualization on the same computational resources as the simulation code, on dedicated visualization clusters or remote workstations, via a standalone rendering client that can be connected or disconnected as needed. We evaluate this system on simulations with up to 227M particles in the LAMMPS and Uintah computational frameworks, and show that our approach provides many of the advantages of tightly-coupled systems, with the flexibility to render on a wide variety of remote and co-processing resources.",
		"teaser_caption": "A coal particle combustion simulation in Uintah at three different timesteps with (left to right): 34.61M, 48.46M and 55.39M particles, with attribute based culling showing the full jet (top) and the front in detail (bottom). Using our in situ library to query and send data to our rendering client in OSPRay these images are rendered interactively with ambient occlusion, averaging around 13 FPS at 1920×1080. The renderer is run on 12 nodes of the Stampede supercomputer and pulls data from a Uintah simulation running on 64 processes (4 nodes). Our loosely-coupled in situ approach allows for live exploration at the full temporal fidelity of the simulation, without prohibitive IO cost."
	},
	{
		"title": "VTK-m: Accelerating the Visualization Toolkit for Massively Threaded Architectures",
		"authors": "Kenneth Moreland, Christopher Sewell, William Usher, Li-ta Lo, Jeremy Meredith,
				David Pugmire, James Kress, Hendrik Schroots, Kwan-Liu Ma, Hank Childs, Matthew Larsen,
				Chun-Ming Chen, Robert Maynard, Berk Geveci",
		"venue": "IEEE Computer Graphics and Applications",
		"paper_pdf": "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7466740",
		"doi": "10.1109/MCG.2016.48",
		"year": 2016,
		"short_title": "vtkm",
		"bibtex": "@article{Moreland_VTKm_2016,\n
			author={K. Moreland and C. Sewell and W. Usher and L. t. Lo and J. Meredith and D. Pugmire and J. Kress and H. Schroots and K. L. Ma and H. Childs and M. Larsen and C. M. Chen and R. Maynard and B. Geveci},\n
			journal={IEEE Computer Graphics and Applications},\n
			title={{VTK-m}: {Accelerating} the {Visualization} {Toolkit} for {Massively} {Threaded} {Architectures}},\n
			year={2016},\n
			volume={36},\n
			number={3},\n
			pages={48-58},\n
			doi={10.1109/MCG.2016.48},\n
			ISSN={0272-1716},\n
			month={May},\n}",
		"abstract": "One of the most critical challenges for high-performance computing (HPC) scientific visualization is execution on massively threaded processors. Of the many fundamental changes we are seeing in HPC systems, one of the most profound is a reliance on new processor types optimized for execution bandwidth over latency hiding. Our current production scientific visualization software is not designed for these new types of architectures. To address this issue, the VTK-m framework serves as a container for algorithms, provides flexible data representation, and simplifies the design of visualization algorithms on new and future computer architecture."
	},
	{
		"title": "CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees",
		"authors": "Ingo Wald, Aaron Knoll, Gregory P. Johnson, Will Usher, Valerio Pasucci, Michael E. Papka",
		"venue": "IEEE Vis (conference)",
		"paper_pdf": "http://sci.utah.edu/~will/papers/pkd/pkd_tree.pdf",
		"doi": "10.1109/SciVis.2015.7429492",
		"teaser": "https://i.imgur.com/1YNpRJ1.png",
		"thumb": "https://i.imgur.com/qpTN5kR.png",
		"gh_user": "ingowald",
		"gh_repo": "ospray-module-pkd",
		"short_title": "pkd",
		"year": 2015,
		"bibtex": "@inproceedings{Wald_PKD_2015,\n
			author={I. Wald and A. Knoll and G. P. Johnson and W. Usher and V. Pascucci and M. E. Papka},\n
			booktitle={2015 IEEE Scientific Visualization Conference (SciVis)},\n
			title={{CPU} ray tracing large particle data with balanced {P-k-d} trees},\n
			year={2015},\n
			pages={57-64},\n
			doi={10.1109/SciVis.2015.7429492},\n
			month={Oct},\n}",
		"abstract": "We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.",
		"teaser_caption": "Full-detail ray tracing of giga-particle data sets. From left to right: CosmicWeb early universe data set from a P3D simulation with 29 billion particles; a 100 million atom molecular dynamics Al<sub>2</sub>O<sub>3</sub>−SiC materials fracture simulation; and a 1.3 billion particle Uintah MPM detonation simulation. Using a quad-socket, 72-core 2.5GHz Intel Xeon E7-8890 v3 Processor with 3TB RAM and path-tracing with progressive refinement at 1 sample per pixel, these far and close images (above and below) are rendered at 1.6 (far) / 1.0 (close) FPS (left), 2.0 / 1.2 FPS (center), and 1.0 / 0.9 FPS (right), respectively, at 4K (3840×2160) resolution. All examples use our balanced P-k-d tree, an acceleration structure which requires little or no memory cost beyond the original data."
	}
]

