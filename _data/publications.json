[
	{
		"title": "A Virtual Reality Visualization Tool for Neuron Tracing",
		"authors": "Will Usher, Pavol Klacansky, Frederick Federer, Peer-Timo Bremer,
				Aaron Knoll, Jeff Yarch, Alessandra Angelucci, and Valerio Pascucci",
		"venue": "IEEE Transactions on Visualization and Computer Graphics",
		"paper_pdf": "http://sci.utah.edu/~will/papers/vrnt/vr-neuron-tracing.pdf",
		"teaser": "https://i.imgur.com/2rmTeh2.png",
		"thumb": "https://i.imgur.com/2iL7UdK.png",
		"year": 2018,
		"short_title": "vrnt",
		"doi": "10.1109/TVCG.2017.2744079",
		"supplemental_video": "https://www.youtube.com/embed/lTNef_kbLKg",
		"presentation_video": "https://www.youtube.com/embed/XzmYdl9rFs0",
		"downloads": [
			{
				"title": "Videos",
				"list": [
					{
						"title": "Analyzing an Expert Session",
						"link": "https://youtu.be/L5tsU8TtgkU"
					},
					{
						"title": "ZED Mixed Reality Prototype",
						"link": "https://youtu.be/t6rPU6hy5tk"
					},
					{
						"title": "VIS17 Fast Forward",
						"link": "https://youtu.be/mZ6YT_y7Kx0"
					}
				]
			}
		],
		"bibtex": "@article{Usher_VRNT_2018,\n
			author={W. Usher and P. Klacansky and F. Federer and P. T. Bremer and A. Knoll and J. Yarch and A. Angelucci and V. Pascucci},\n
			journal={IEEE Transactions on Visualization and Computer Graphics},\n
			title={A {Virtual} {Reality} {Visualization} {Tool} for {Neuron} {Tracing}},\n
			year={2018},\n
			volume={24},\n
			number={1},\n
			pages={994-1003},\n
			doi={10.1109/TVCG.2017.2744079},\n
			ISSN={1077-2626},\n
			month={Jan},\n}",
		"abstract": "Tracing neurons in large-scale microscopy data is crucial to establishing a wiring diagram of the brain, which is needed to understand how neural circuits in the brain process information and generate behavior. Automatic techniques often fail for large and complex datasets, and connectomics researchers may spend weeks or months manually tracing neurons using 2D image stacks. We present a design study of a new virtual reality (VR) system, developed in collaboration with trained neuroanatomists, to trace neurons in microscope scans of the visual cortex of primates. We hypothesize that using consumer-grade VR technology to interact with neurons directly in 3D will help neuroscientists better resolve complex cases and enable them to trace neurons faster and with less physical and mental strain. We discuss both the design process and technical challenges in developing an interactive system to navigate and manipulate terabyte-sized image volumes in VR. Using a number of different datasets, we demonstrate that, compared to widely used commercial software, consumer-grade VR presents a promising alternative for scientists.",
		"teaser_caption": "A screenshot of our VR neuron tracing tool using the isosurface rendering mode. The dark gray floor represents the extent of the tracked space. Users can orient themselves in the dataset via the minimap (right), which shows the world extent in blue, the current focus region in orange, and the previously traced neuronal structures. The focus region is displayed in the center of the space. The 3D interaction and visualization provides an intuitive environment for exploring the data and a natural interface for neuron tracing, resulting in faster, high-quality traces with less fatigue reported by users compared to existing 2D tools."
	},
	{
		"title": "VisIt-OSPRay: Toward an Exascale Volume Visualization System",
		"authors": "Qi Wu, Will Usher, Steve Petruzza, Sidharth Kumar, Feng Wang,
			Ingo Wald, Valerio Pascucci, and Charles D. Hansen",
		"venue": "Eurographics Symposium on Parallel Graphics and Visualization",
		"paper_pdf": "http://sci.utah.edu/~will/papers/visit-ospray-egpgv18.pdf",
		"teaser": "https://i.imgur.com/JgAOmst.png",
		"thumb": "https://i.imgur.com/RxCFTxo.jpg",
		"year": 2018,
		"short_title": "visit-ospray",
		"doi": "10.2312/pgv.20181091",
		"bibtex": "@inproceedings{Wu_VisItOSPRay_2018,\n
			booktitle = {Eurographics Symposium on Parallel Graphics and Visualization},\n
			editor = {Hank Childs and Fernando Cucchietti},\n
			title = {{VisIt-OSPRay: Toward an Exascale Volume Visualization System}},\n
			author = {Wu, Qi and Usher, Will and Petruzza, Steve and Kumar, Sidharth and Wang, Feng and Wald, Ingo and Pascucci, Valerio and Hansen, Charles D.},\n
			year = {2018},\n
			publisher = {The Eurographics Association},\n
			ISSN = {1727-348X},\n
			ISBN = {978-3-03868-054-3},\n
			DOI = {10.2312/pgv.20181091}\n
		}",
		"abstract": "Large-scale simulations can easily produce data in excess of what can be
		efficiently visualized using production visualization software, making it
		challenging for scientists to gain insights from the results of these 
		simulations.
		This trend is expected to grow with exascale. To meet this challenge,
		and run on the highly parallel hardware being deployed on HPC system,
		rendering systems in production visualization software must be redesigned
		to perform well at these new scales and levels of parallelism.
		In this work, we present VisIt-OSPRay, a high-performance,
		scalable, hybrid-parallel rendering system in VisIt, using OSPRay and IceT, 
		coupled with PIDX for scalable I/O. 
		We examine the scalability and memory efficiency of this system and 
		investigate further areas for improvement to prepare VisIt for 
		upcoming exascale workloads.",
		"teaser_caption": "High-quality interactive volume visualization using VisIt-OSPRay:
		<b>a)</b> volume rendering of O<sub>2</sub> concentration inside a combustion chamber,
		data courtesy of the <a href=\"http://ccmsc.sci.utah.edu/\">University of Utah CCMSC</a>;
		<b>b)</b> volume rendering of the Richtmyer-Meshkov Instability;
		<b>c)</b> visualization of a supernova simulation;
		<b>d)</b> visualization of the aneurysm dataset using volume rendering and streamlines;
		<b>e)</b> scalable volume rendering of the 966GB DNS data on 64 Stampede2 Intel Xeon Phi
		Knight's Landing nodes."
	},
	{
		"title": "Scalable Data Management of the Uintah Simulation Framework for Next-Generation Engineering Problems with Radiation",
		"authors": "Sidharth Kumar, Alan Humphrey, Will Usher, Steve Petruzza
				Brad Peterson, John A. Schmidt, Derek Harris, Ben Isaac,
				Jeremy Thornock, Todd Harman, Valerio Pascucci, and Martin Berzins",
		"venue": "Supercomputing Frontiers",
		"paper_pdf": "http://sci.utah.edu/~will/papers/scasia18.pdf",
		"thumb": "https://i.imgur.com/w5YWvd6.png",
		"year": 2018,
		"short_title": "scasia18",
		"doi": "10.1007/978-3-319-69953-0_13",
		"downloads": [
			{
				"title": "Videos",
				"list": [
					{
						"title": "Uintah UASC Coal Boiler Visualization",
						"link": "https://youtu.be/vpJtHTzArq4"
					}
				]
			}
		],
		"bibtex": "@incollection{kumar_scalable_2018,\n
			title = {Scalable {Data} {Management} of the {Uintah} {Simulation} {Framework} for {Next}-{Generation} {Engineering} {Problems} with {Radiation}},\n
			volume = {10776},\n
			isbn = {978-3-319-69952-3 978-3-319-69953-0},\n
			booktitle = {Supercomputing {Frontiers}},\n
			publisher = {Springer International Publishing},\n
			author = {Kumar, Sidharth and Humphrey, Alan and Usher, Will and Petruzza, Steve and Peterson, Brad and Schmidt, John A. and Harris, Derek and Isaac, Ben and Thornock, Jeremy and Harman, Todd and Pascucci, Valerio and Berzins, Martin},\n
			editor = {Yokota, Rio and Wu, Weigang},\n
			year = {2018},\n
			doi = {10.1007/978-3-319-69953-0_13},\n
			pages = {219--240},\n}",
			"abstract": "The need to scale next-generation industrial engineering
				problems to the largest computational platforms presents unique challenges.
				This paper focuses on data management related problems faced
				by the Uintah simulation framework at a production scale of 260K processes.
				Uintah provides a highly scalable asynchronous many-task runtime
				system, which in this work is used for the modeling of a 1000
				megawatt electric (MWe) ultra-supercritical (USC) coal boiler. At 260K
				processes, we faced both parallel I/O and visualization related challenges,
				e.g., the default file-per-process I/O approach of Uintah did not scale
				on Mira. In this paper we present a simple to implement, restructuring
				based parallel I/O technique. We impose a restructuring step that
				alters the distribution of data among processes. The goal is to distribute
				the dataset such that each process holds a larger chunk of data, which is
				then written to a file independently. This approach finds a middle ground
				between two of the most common parallel I/O schemes–file per process
				I/O and shared file I/O–in terms of both the total number of generated
				files, and the extent of communication involved during the data aggregation
				phase. To address scalability issues when visualizing the simulation
				data, we developed a lightweight renderer using OSPRay, which allows
				scientists to visualize the data interactively at high quality and make
				production movies. Finally, this work presents a highly efficient and scalable
				radiation model based on the sweeping method, which significantly
				outperforms previous approaches in Uintah, like discrete ordinates. The
				integrated approach allowed the USC boiler problem to run on 260K
				CPU cores on Mira."
	},
	{
		"title": "CPU Volume Rendering of Adaptive Mesh Refinement Data",
		"authors": "Ingo Wald, Carson Brownlee, Will Usher, Aaron Knoll",
		"venue": "SIGGRAPH Asia 2017 Symposium on Visualization",
		"paper_pdf": "http://sci.utah.edu/~will/papers/cvamr/cvamr.pdf",
		"teaser": "https://i.imgur.com/CqZc3VJ.png",
		"thumb": "https://i.imgur.com/JFShB4G.png",
		"year": 2017,
		"short_title": "cvamr",
		"doi": "10.1145/3139295.3139305",
		"bibtex": "@inproceedings{Wald_CVAMR_2017,\n
			author = {Wald, Ingo and Brownlee, Carson and Usher, Will and Knoll, Aaron},\n
			title = {CPU Volume Rendering of Adaptive Mesh Refinement Data},\n
			booktitle = {SIGGRAPH Asia 2017 Symposium on Visualization},\n
			series = {SA '17},\n
			year = {2017},\n
			isbn = {978-1-4503-5411-0},\n
			location = {Bangkok, Thailand},\n
			pages = {9:1--9:8},\n
			articleno = {9},\n
			numpages = {8},\n
			url = {http://doi.acm.org/10.1145/3139295.3139305},\n
			doi = {10.1145/3139295.3139305},\n
			acmid = {3139305},\n
			publisher = {ACM},\n
			address = {New York, NY, USA},\n
		}",
		"abstract": "Adaptive Mesh Refinement (AMR) methods are widespread
		in scientific computing, and visualizing the resulting data with
		efficient and accurate rendering methods can be vital for enabling 
		interactive data exploration.
		In this work, we
		detail a comprehensive solution for directly volume rendering block-structured 
		(Berger-Colella) AMR data in the
		OSPRay interactive CPU ray tracing framework. In particular, we
		contribute a general method for representing and traversing AMR data
		using a kd-tree structure, and four different reconstruction
		options, one of which in particular (the basis function approach)
		is novel compared to existing methods. We demonstrate our system on two
		types of block-structured AMR data and compressed scalar
		field data, and show how it can be easily used in existing production-ready
		applications through a prototypical integration in the widely used visualization program ParaView.",
		"teaser_caption": "Two examples of our method (integrated within the OSPRay ray tracer):
		Left: 1.8GB Cosmos AMR data, rendered in ParaView. Right: a 57GB NASA Chombo simulation,
		rendered with ambient occlusion and shadows alongside mesh geometry."
	},
	{
		"title": "Progressive CPU Volume Rendering with Sample Accumulation",
		"authors": "Will Usher, Jefferson Amstutz, Carson Brownlee, Aaron Knoll, Ingo Wald",
		"venue": "Eurographics Symposium on Parallel Graphics and Visualization",
		"paper_pdf": "http://sci.utah.edu/~will/papers/savr/savr.pdf",
		"teaser": "https://i.imgur.com/15y1f8I.png",
		"thumb": "https://i.imgur.com/tdxjYs3.png",
		"short_title": "savr",
		"doi": "10.2312/pgv.20171090",
		"gh_user": "ospray",
		"gh_repo": "module_savr",
		"year": 2017,
		"bibtex": "@inproceedings{Usher_SAVR_2017,\n
			booktitle={Eurographics Symposium on Parallel Graphics and Visualization},\n
			editor={Alexandru Telea and Janine Bennett},\n
			title={{Progressive CPU Volume Rendering with Sample Accumulation}},\n
			author={Usher, Will and Amstutz, Jefferson and Brownlee, Carson and Knoll, Aaron and Wald, Ingo},\n
			year={2017},\n
			publisher={The Eurographics Association},\n
			issn={1727-348X},\n
			isbn={978-3-03868-034-5},\n
			doi={10.2312/pgv.20171090},\n}",
		"abstract": "We present a new method for progressive volume rendering by accumulating object-space samples over successively rendered frames. Existing methods for progressive refinement either use image space methods or average pixels over frames, which can blur features or integrate incorrectly with respect to depth. Our approach stores samples along each ray, accumulates new samples each frame into a buffer, and progressively interleaves and integrates these samples. Though this process requires additional memory, it ensures interactivity and is well suited for CPU architectures with large memory and cache. This approach also extends well to distributed rendering in cluster environments. We implement this technique in Intel’s open source OSPRay CPU ray tracing framework and demonstrate that it is particularly useful for rendering volumetric data with costly sampling functions.",
		"teaser_caption": "(a-c) Progressive refinement with Sample-Accumulation Volume Rendering (SAVR) on the 40GB Landing Gear AMR dataset using a prototype AMR sampler. The SAVR algorithm correctly accumulates frames to progressively refine the image. After 16 frames of accumulation the volume is sampled at the Nyquist limit, with some small noise, by 32 frames the noise has been removed. SAVR extends to distributed data, in (d) we show the 1TB DNS dataset, a 10240×7680×1536 uniform grid, rendered interactively across 64 second-generation Intel Xeon Phi \"Knights Landing\" (KNL) processor nodes on Stampede 1.5 at a 6144×1024 resolution. While interacting, our method achieves around 5.73 FPS."
	},
	{
		"title": "In Situ Exploration of Particle Simulations with CPU Ray Tracing",
		"authors": "Will Usher, Ingo Wald, Aaron Knoll, Michael Papka, Valerio Pascucci",
		"venue": "Supercomputing Frontiers and Innovations",
		"paper_pdf": "http://sci.utah.edu/~will/papers/in_situ_particles/in_situ_particles.pdf",
		"teaser": "https://i.imgur.com/DO3JqOb.png",
		"thumb": "https://i.imgur.com/gieTAy3.png",
		"short_title": "isp-jsfi",
		"doi": "10.14529/jsfi160401",
		"gh_user": "Twinklebear",
		"gh_repo": "in-situ-particles",
		"year": 2016,
		"bibtex": "@article{Usher_InSituParticles_2016,\n
			author={Will Usher and Ingo Wald and Aaron Knoll and Michael Papka and Valerio Pascucci},\n
			title={In {Situ} {Exploration} of {Particle} {Simulations} with {CPU} {Ray} {Tracing}},\n
			journal={Supercomputing Frontiers and Innovations},\n
			volume={3},\n
			number={4},\n
			year={2016},\n
			issn={2313-8734},\n
			doi={10.14529/jsfi160401},\n}",
		"abstract": "We present a system for interactive in situ visualization of large particle simulations, suitable for general CPU-based HPC architectures. As simulations grow in scale, in situ methods are needed to alleviate IO bottlenecks and visualize data at full spatio-temporal resolution. We use a lightweight loosely-coupled layer serving distributed data from the simulation to a data-parallel renderer running in separate processes. Leveraging the OSPRay ray tracing framework for visualization and balanced P-k-d trees, we can render simulation data in real-time, as they arrive, with negligible memory overhead. This flexible solution allows users to perform exploratory in situ visualization on the same computational resources as the simulation code, on dedicated visualization clusters or remote workstations, via a standalone rendering client that can be connected or disconnected as needed. We evaluate this system on simulations with up to 227M particles in the LAMMPS and Uintah computational frameworks, and show that our approach provides many of the advantages of tightly-coupled systems, with the flexibility to render on a wide variety of remote and co-processing resources.",
		"teaser_caption": "A coal particle combustion simulation in Uintah at three different timesteps with (left to right): 34.61M, 48.46M and 55.39M particles, with attribute based culling showing the full jet (top) and the front in detail (bottom). Using our in situ library to query and send data to our rendering client in OSPRay these images are rendered interactively with ambient occlusion, averaging around 13 FPS at 1920×1080. The renderer is run on 12 nodes of the Stampede supercomputer and pulls data from a Uintah simulation running on 64 processes (4 nodes). Our loosely-coupled in situ approach allows for live exploration at the full temporal fidelity of the simulation, without prohibitive IO cost."
	},
	{
		"title": "VTK-m: Accelerating the Visualization Toolkit for Massively Threaded Architectures",
		"authors": "Kenneth Moreland, Christopher Sewell, William Usher, Li-ta Lo, Jeremy Meredith,
				David Pugmire, James Kress, Hendrik Schroots, Kwan-Liu Ma, Hank Childs, Matthew Larsen,
				Chun-Ming Chen, Robert Maynard, Berk Geveci",
		"venue": "IEEE Computer Graphics and Applications",
		"paper_pdf": "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7466740",
		"doi": "10.1109/MCG.2016.48",
		"year": 2016,
		"short_title": "vtkm",
		"bibtex": "@article{Moreland_VTKm_2016,\n
			author={K. Moreland and C. Sewell and W. Usher and L. t. Lo and J. Meredith and D. Pugmire and J. Kress and H. Schroots and K. L. Ma and H. Childs and M. Larsen and C. M. Chen and R. Maynard and B. Geveci},\n
			journal={IEEE Computer Graphics and Applications},\n
			title={{VTK-m}: {Accelerating} the {Visualization} {Toolkit} for {Massively} {Threaded} {Architectures}},\n
			year={2016},\n
			volume={36},\n
			number={3},\n
			pages={48-58},\n
			doi={10.1109/MCG.2016.48},\n
			ISSN={0272-1716},\n
			month={May},\n}",
		"abstract": "One of the most critical challenges for high-performance computing (HPC) scientific visualization is execution on massively threaded processors. Of the many fundamental changes we are seeing in HPC systems, one of the most profound is a reliance on new processor types optimized for execution bandwidth over latency hiding. Our current production scientific visualization software is not designed for these new types of architectures. To address this issue, the VTK-m framework serves as a container for algorithms, provides flexible data representation, and simplifies the design of visualization algorithms on new and future computer architecture."
	},
	{
		"title": "CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees",
		"authors": "Ingo Wald, Aaron Knoll, Gregory P. Johnson, Will Usher, Valerio Pasucci, Michael E. Papka",
		"venue": "IEEE Vis (conference)",
		"paper_pdf": "http://sci.utah.edu/~will/papers/pkd/pkd_tree.pdf",
		"doi": "10.1109/SciVis.2015.7429492",
		"teaser": "https://i.imgur.com/1YNpRJ1.png",
		"thumb": "https://i.imgur.com/qpTN5kR.png",
		"gh_user": "ingowald",
		"gh_repo": "ospray-module-pkd",
		"short_title": "pkd",
		"year": 2015,
		"bibtex": "@inproceedings{Wald_PKD_2015,\n
			author={I. Wald and A. Knoll and G. P. Johnson and W. Usher and V. Pascucci and M. E. Papka},\n
			booktitle={2015 IEEE Scientific Visualization Conference (SciVis)},\n
			title={{CPU} ray tracing large particle data with balanced {P-k-d} trees},\n
			year={2015},\n
			pages={57-64},\n
			doi={10.1109/SciVis.2015.7429492},\n
			month={Oct},\n}",
		"abstract": "We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.",
		"teaser_caption": "Full-detail ray tracing of giga-particle data sets. From left to right: CosmicWeb early universe data set from a P3D simulation with 29 billion particles; a 100 million atom molecular dynamics Al<sub>2</sub>O<sub>3</sub>−SiC materials fracture simulation; and a 1.3 billion particle Uintah MPM detonation simulation. Using a quad-socket, 72-core 2.5GHz Intel Xeon E7-8890 v3 Processor with 3TB RAM and path-tracing with progressive refinement at 1 sample per pixel, these far and close images (above and below) are rendered at 1.6 (far) / 1.0 (close) FPS (left), 2.0 / 1.2 FPS (center), and 1.0 / 0.9 FPS (right), respectively, at 4K (3840×2160) resolution. All examples use our balanced P-k-d tree, an acceleration structure which requires little or no memory cost beyond the original data."
	}
]

